Capítulo 4: Búsqueda No Informada (Ciega)
Búsqueda en Anchura (Breadth-First Search, BFS): Este algoritmo explora todos los nodos a nivel de profundidad 1 antes de proceder a los nodos a nivel 2, y así sucesivamente. Es un algoritmo que garantiza encontrar la solución más corta en términos de número de pasos, pero puede ser muy ineficiente si el espacio de búsqueda es grande, ya que almacena todos los nodos generados. Es especialmente útil cuando los pasos o costes de las acciones son uniformes.

Búsqueda en Profundidad (Depth-First Search, DFS): A diferencia de la búsqueda en anchura, la búsqueda en profundidad sigue un camino desde el nodo inicial hasta el final, explorando tan profundamente como sea posible antes de retroceder y explorar otros caminos. Es más eficiente en términos de memoria, pero no garantiza encontrar la solución más corta ni puede ser útil si el espacio de búsqueda tiene ciclos, lo que podría llevar a un ciclo infinito sin una estrategia de control.

Búsqueda en Coste Uniforme (Uniform Cost Search, UCS): Este algoritmo expande siempre el nodo con el coste más bajo hasta el objetivo. Es una variante de la búsqueda en anchura pero que tiene en cuenta el coste de las acciones, no solo la profundidad. Garantiza encontrar la solución con el menor coste, pero puede ser costoso en términos de memoria si hay muchos caminos con distintos costes. Es ideal cuando se tiene información sobre los costes de las transiciones entre estados.

Búsqueda Iterativa en Profundidad (Iterative Deepening Search, IDS): Combina las ventajas de la búsqueda en profundidad y la búsqueda en anchura. Realiza una serie de búsquedas en profundidad con un límite de profundidad creciente. Primero explora todos los nodos a una profundidad 1, luego a una profundidad 2, y así sucesivamente. Esta técnica es útil cuando no se conoce la profundidad del objetivo y es más eficiente en memoria que la búsqueda en anchura.

Capítulo 5: Búsqueda Informada (Heurística)
Búsqueda A*: Es uno de los algoritmos más conocidos en IA, que utiliza tanto el coste acumulado del camino desde el nodo inicial (g(n)) como una estimación del coste restante hacia la meta (h(n)) para decidir qué nodo explorar a continuación. El algoritmo selecciona el nodo con el valor mínimo de f(n) = g(n) + h(n). La búsqueda A* es óptima y completa si la heurística utilizada es admisible (no sobreestima el coste al objetivo). Es altamente eficiente en la búsqueda de soluciones en espacios grandes.

Búsqueda Greedy (Greedy Search): Este algoritmo toma decisiones basadas solo en la heurística (h(n)), es decir, selecciona el nodo que parece más cercano a la solución, según la estimación del coste desde ese nodo al objetivo. Aunque puede ser muy rápida, no garantiza encontrar la solución óptima porque puede quedar atrapada en un camino que parece prometedor pero no lo es, ya que no tiene en cuenta el coste real hasta el nodo inicial.

Búsqueda A* con Heurística de Búsqueda Local (A* with Local Search Heuristic): Esta variante de A* es utilizada cuando la heurística local se utiliza para guiar el algoritmo, lo que puede reducir significativamente la cantidad de nodos explorados. En lugar de realizar una exploración exhaustiva, se toma en cuenta el costo de las acciones y se ajusta la búsqueda según las características locales del espacio de búsqueda.

Capítulo 6: Búsqueda Local y Optimización
Búsqueda Local (Local Search): Este tipo de búsqueda trabaja moviéndose de un estado a otro, evaluando cuál es el mejor vecino según alguna función de coste o rendimiento. Es útil cuando el espacio de búsqueda es muy grande y no se puede representar de manera explícita todo el espacio. A menudo se utiliza en problemas donde la solución no tiene una estructura jerárquica clara, como en la optimización de funciones matemáticas o problemas de programación.

Descenso de Gradiente (Gradient Descent): En este algoritmo, la idea es moverse hacia la dirección de la pendiente más pronunciada de la función de coste, lo que significa que se ajustan los parámetros del problema siguiendo la dirección opuesta al gradiente. Es muy usado en problemas de optimización continua, como en el entrenamiento de redes neuronales, aunque tiene el riesgo de quedar atrapado en óptimos locales.

Simulated Annealing (Recocido Simulado): Basado en el proceso físico de enfriamiento del metal, este algoritmo de optimización estocástico permite la posibilidad de "aceptar" soluciones peores temporalmente, con la esperanza de escapar de los óptimos locales. La probabilidad de aceptar una solución peor disminuye con el tiempo, de modo que el algoritmo gradualmente se enfoca en explorar soluciones más cercanas a la óptima global.

Algoritmo de Colonia de Hormigas (Ant Colony Optimization, ACO): Este algoritmo se inspira en el comportamiento de las colonias de hormigas en la naturaleza, donde las hormigas depositan feromonas para guiar a otras hormigas hacia caminos más cortos. Utiliza este comportamiento para resolver problemas de optimización como el problema del vendedor viajero, en el que las hormigas "exploran" el espacio de soluciones y refuerzan los caminos más prometedores con más feromonas.